{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3zV/1VrFzttkGdU4zA6e4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishmudliyar/DS-Experiment/blob/main/Experiment_11_Saish_Mudliyar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 11"
      ],
      "metadata": {
        "id": "gGMNAIVo0d9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging\n",
        "Randomforest"
      ],
      "metadata": {
        "id": "M_7L48g10fXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Bagging and RandomForest models\n",
        "bagging_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Bagging model\n",
        "bagging_model.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "# Train the Random Forest model\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# Output the accuracy results\n",
        "print(f\"Bagging model accuracy: {bagging_accuracy:.4f}\")\n",
        "print(f\"Random Forest model accuracy: {rf_accuracy:.4f}\")\n",
        "\n",
        "# Feature importance from Random Forest\n",
        "importances = random_forest_model.feature_importances_\n",
        "print(f\"Feature importances from Random Forest: {importances}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxWTYBnl0gdT",
        "outputId": "a826479a-938a-492c-86c5-de01178b95b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging model accuracy: 1.0000\n",
            "Random Forest model accuracy: 1.0000\n",
            "Feature importances from Random Forest: [0.10410501 0.04460499 0.41730813 0.43398187]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting\n",
        "Xgboost"
      ],
      "metadata": {
        "id": "EA5ThX0U0vgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVWUM4cl0vaq",
        "outputId": "926dfcd7-f6bc-470e-c537-c5fac94485d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Output the accuracy result\n",
        "print(f\"XGBoost model accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "# Feature importance from XGBoost\n",
        "importances_xgb = xgb_model.feature_importances_\n",
        "print(f\"Feature importances from XGBoost: {importances_xgb}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VudPjKO91BRQ",
        "outputId": "49879b1f-82ed-40ef-e90c-d94548bb0e82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:54:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost model accuracy: 1.0000\n",
            "Feature importances from XGBoost: [0.01012843 0.0303854  0.73876214 0.22072402]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking\n",
        "Logistic regressor and KNN"
      ],
      "metadata": {
        "id": "W7wfld781ExS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the base models (Logistic Regression and KNN)\n",
        "base_learners = [\n",
        "    ('logreg', LogisticRegression(max_iter=1000)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "]\n",
        "\n",
        "# Initialize the meta-model (Logistic Regression)\n",
        "meta_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Create the Stacking model\n",
        "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
        "\n",
        "# Train the stacking model\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the stacking model\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "stacking_accuracy = accuracy_score(y_test, y_pred_stacking)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Stacking model accuracy: {stacking_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q3wBEd-1Etc",
        "outputId": "f76b09a5-1186-469b-8c86-7b3d1de7cf01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking model accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}